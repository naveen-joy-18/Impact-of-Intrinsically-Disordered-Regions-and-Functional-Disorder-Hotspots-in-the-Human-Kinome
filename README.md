# Impact-of-Intrinsically-Disordered-Regions-and-Functional-Disorder-Hotspots-in-the-Human-Kinome
Human kinase-focused IDR prediction framework using an LSTM model . It maps IDRs across the human kinome, classifies them by length, and analyzes their conservation and regulatory role. We identified 1,039 functional hotspots linked to signaling, phosphorylation, and drug targeting
## Table of Contents

- [Project Overview](#project-overview)
- [Files in this Repository](#files-in-this-repository)
- [Visualizations](#visualizations)
- [How to Use](#how-to-use)
  - [Environment Setup](#environment-setup)
  - [Running the Project](#running-the-project)
- [Results and Analysis](#results-and-analysis)

## Project Overview

The core of this project is to develop and evaluate a machine learning model for predicting intrinsically disordered regions (IDRs) in proteins. IDRs are crucial for various biological functions but lack a fixed three-dimensional structure. The project leverages an LSTM neural network, a type of recurrent neural network well-suited for sequential data like protein sequences. The workflow encompasses data preparation, model training, performance evaluation against established benchmarks, and generating predictions.

## Files in this Repository

Here's a detailed explanation of each file included in this repository:

-   `DisorderPredictionCode.ipynb`: This is the primary Jupyter Notebook that orchestrates the entire project. It contains all the Python code for:
    -   **Data Loading and Preprocessing**: Reading raw protein sequence data from Excel files, cleaning it, and transforming it into a numerical format suitable for the LSTM model. This includes steps like one-hot encoding or embedding amino acid sequences and preparing input features and target labels.
    -   **Model Definition**: Defining the architecture of the LSTM neural network, including layers, activation functions, and output structure.
    -   **Model Training**: The process of feeding the preprocessed data to the LSTM model to learn patterns and make predictions. This involves specifying training parameters like epochs, batch size, and optimization algorithms.
    -   **Model Evaluation**: Assessing the trained model's performance using various metrics such as accuracy, loss, and Receiver Operating Characteristic (ROC) curves. This section also includes code to generate the visualization SVG files.
    -   **Comparison with Existing Tools**: Code to load results from other disorder prediction tools and compare the LSTM model's performance against them, typically through ROC curve analysis.
    -   **Prediction Generation**: Applying the trained model to new, unseen protein sequences to predict their disorder status and saving the results.

-   `disorder_prediction_model.pkl`: This file is a serialized (pickled) Python object representing the **trained LSTM model**. After the `DisorderPredictionCode.ipynb` notebook is run and the model is trained, it is saved to this file. You can load this file directly into a Python environment to use the pre-trained model for new predictions without retraining.

-   `OriginalTraining.xlsx`: This Excel file contains the **original dataset used for training** the disorder prediction model. It likely includes protein sequences and their corresponding experimentally determined disorder annotations (e.g., 'disordered' or 'ordered' labels for each residue or region).

-   `OriginalUniprot.xlsx`: This Excel file likely contains **additional protein sequences from the UniProt database**. It might be used for validation, testing, or as a source of new sequences for prediction after the model has been trained. It may or may not contain disorder annotations, depending on its purpose in the project.

-   `Predicted_disorder_output0.25Threshold.xlsx`: This Excel file contains the **output of the disorder prediction** generated by the trained model. It shows the predicted disorder status for proteins, likely based on a probability threshold of 0.25. For each protein or residue, it would indicate whether it's predicted as disordered or ordered.

-   `processed_data.pkl`: This file is a serialized Python object containing the **processed data** that is ready for direct input into the LSTM model. This typically includes numerical representations of protein sequences (e.g., one-hot encoded or embedded amino acid features) and their corresponding labels, after all preprocessing steps (like feature extraction, padding, etc.) have been applied by the Jupyter notebook.

-   `scaler.pkl`: This file is a serialized Python object representing the **feature scaler** used during data preprocessing. In machine learning, features are often scaled (e.g., normalized or standardized) to improve model performance. This `scaler.pkl` file allows you to apply the exact same scaling transformation to new data before feeding it to the trained model, ensuring consistency.

## Visualizations

The following SVG files are generated during the model evaluation phase and provide insights into the model's performance and comparisons:

-   `accuracy_curve.svg`: A plot illustrating the **training accuracy and validation accuracy** of the LSTM model over each training epoch. This helps in understanding if the model is learning effectively and if there's any overfitting.
-   `loss_curve.svg`: A plot showing the **training loss and validation loss** of the LSTM model over each training epoch. This indicates how well the model is minimizing errors during training and on unseen data.
-   `roc_curve.svg`: The **Receiver Operating Characteristic (ROC) curve** for the LSTM model. This plot visualizes the trade-off between the true positive rate (sensitivity) and the false positive rate (1-specificity) at various threshold settings. A higher Area Under the Curve (AUC) indicates better model performance.
-   `idr_roc_comparison.svg`: An ROC curve specifically comparing the performance of your LSTM model for **Intrinsically Disordered Regions (IDR) prediction** against another tool, likely FLDPnn, as indicated by the plot.
-   `roc_lstm_vs_adopt.svg`: An ROC curve comparing the LSTM model's performance against the **ADOPT** disorder prediction tool.
-   `roc_lstm_vs_aiupred.svg`: An ROC curve comparing the LSTM model's performance against the **AIUpred-binding** disorder prediction tool.
-   `roc_lstm_vs_disoflag.svg`: An ROC curve comparing the LSTM model's performance against the **DisoFLAG** disorder prediction tool.
-   `roc_lstm_vs_fldpnn.svg`: An ROC curve comparing the LSTM model's performance against the **FLDPnn** disorder prediction tool.
-   `roc_lstm_vs_fldpnn2.svg`: An ROC curve comparing the LSTM model's performance against the **FLDPnn2** disorder prediction tool.

## How to Use

To replicate the results, train the model, or use it for new predictions, follow these steps:

### Environment Setup

1.  **Install Python**: Ensure you have Python (preferably Python 3.8 or newer) installed on your system. You can download it from [python.org](https://www.python.org/downloads/).

2.  **Install Jupyter**: Jupyter Notebook or Jupyter Lab is required to run the `.ipynb` file. Install it using pip:
    ```bash
    pip install jupyter
    ```

3.  **Install Required Libraries**: The project relies on several Python libraries for data manipulation, machine learning, and plotting. Install them using pip:
    ```bash
    pip install tensorflow pandas scikit-learn numpy matplotlib seaborn openpyxl
    ```
    *   `tensorflow`: For building and training the LSTM neural network.
    *   `pandas`: For data manipulation and reading Excel files.
    *   `scikit-learn`: For various machine learning utilities, including data preprocessing and evaluation metrics.
    *   `numpy`: For numerical operations.
    *   `matplotlib` and `seaborn`: For creating the various plots and visualizations.
    *   `openpyxl`: To handle `.xlsx` Excel files.

### Running the Project

1.  **Launch Jupyter**: Open your terminal or command prompt, navigate to the directory where you have saved the project files, and launch Jupyter:
    ```bash
    jupyter notebook
    ```
    or
    ```bash
    jupyter lab
    ```
    This will open a new tab in your web browser with the Jupyter interface.

2.  **Open the Notebook**: In the Jupyter interface, locate and click on `DisorderPredictionCode.ipynb` to open it.

3.  **Run All Cells**: To execute the entire workflow (data loading, preprocessing, model training, evaluation, and prediction), go to the Jupyter menu, click on `Cell`, and then select `Run All`.

    *Alternatively, you can run cells individually by selecting a cell and pressing `Shift + Enter`.* 

    Running the notebook will:
    -   Load data from `OriginalTraining.xlsx` and potentially `OriginalUniprot.xlsx`.
    -   Perform all necessary data preprocessing steps.
    -   Train the LSTM model.
    -   Generate and save the `accuracy_curve.svg`, `loss_curve.svg`, `roc_curve.svg`, and all comparison ROC curve SVG files in the same directory.
    -   Save the trained model as `disorder_prediction_model.pkl`.
    -   Save the processed data as `processed_data.pkl`.
    -   Save the feature scaler as `scaler.pkl`.
    -   Generate and save the prediction results to `Predicted_disorder_output0.25Threshold.xlsx`.

## Results and Analysis

The generated SVG plots provide a comprehensive overview of the model's performance and its comparison with existing tools:

-   **Accuracy and Loss Curves (`accuracy_curve.svg`, `loss_curve.svg`)**: These plots are essential for monitoring the training process. The accuracy curve shows how well the model is performing on both training and validation datasets over time, while the loss curve indicates the error rate. Ideally, both training and validation curves should converge, and a small gap between them suggests good generalization without significant overfitting.

-   **ROC Curves (`roc_curve.svg`, `idr_roc_comparison.svg`, `roc_lstm_vs_*.svg`)**: ROC curves are a standard metric for evaluating binary classifiers. The closer the curve is to the top-left corner, and the higher the Area Under the Curve (AUC) value, the better the model's ability to distinguish between disordered and ordered regions. The comparison plots clearly demonstrate how the developed LSTM model performs relative to other established disorder prediction tools, highlighting its strengths and potential improvements. For instance, an AUC of 0.97 for the LSTM model (as seen in `roc_curve.svg`) indicates excellent predictive power.

For a detailed understanding of the model's architecture, specific preprocessing steps, and the exact evaluation metrics, please refer to the `DisorderPredictionCode.ipynb` notebook itself.


